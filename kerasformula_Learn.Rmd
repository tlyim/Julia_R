---
title: "Learn kerasformula and Keras"
output: html_notebook
---

 
**kerasformula** sample code
```{r}
#devtools::install_github("rstudio/keras")
#install.packages("kerasformula")
library(kerasformula)
#install_keras()

```


```{r}

```


```{r}

```


```{r}

```




**bigKRLS** sample code

```{r}
#install.packages(c("Rcpp", "RcppArmadillo", "bigmemory", "biganalytics", "snow", "shiny", "httpuv", "scales", "lazyeval", "tibble"))
#devtools::install_github('rdrr1990/bigKRLS')
library(bigKRLS)
vignette("bigKRLS_basics")
```

bigKRLS() and plotting
```{r}

mtcars[1:5,]

reg.out <- bigKRLS(y = as.matrix(mtcars$mpg), 
                   X = as.matrix(mtcars[,-1]), Ncores = 1)

summary(reg.out)

s <- reg.out$K[which(mtcars$cyl == 4), grep("Corolla", rownames(mtcars))]

barplot(s, main = "Similarity to a Toyota Corolla",
        ylab = "Kernel", sub="Toy Data from mtcars", cex.names = .7,
        col = colorRampPalette(c("red", "blue"))(length(s))[rank(s)],
        names.arg = lapply(strsplit(rownames(mtcars), split=" "),
                           function(x) x[2])[which(mtcars$cyl == 4)])
scatter.smooth(mtcars$hp, reg.out$derivatives[,3], ylab="HP's Effect", xlab="Horsepower", pch =19, bty = "n",
               main="Horsepower's Marginal Effect on Fuel Efficiency",
               sub="Toy Data from mtcars",
               col = colorRampPalette(c("blue", "red"))(nrow(mtcars))[rank(reg.out$coeffs^2)],
               ylim = c(-0.042, 0.015), xlim = c(50, 400))

```


Cross-Validation, In-sample and out-of-sample statistics, and Out-of-Sample prediction
```{r}

# Cross-Validation
CV.out <- crossvalidate.bigKRLS(y = as.matrix(mtcars$mpg), seed = 123, Kfolds = 4,
                                X = as.matrix(mtcars[,-1]), Ncores = 1)
summary(CV.out$fold_1$trained)


#In-sample and out-of-sample statistics
CV.out$MSE_is
CV.out$MSE_oos
CV.out$R2_oos
CV.out$R2AME_oos


#Predicting with Out-of-Sample Data
Xnew <- mtcars[,-1]
Xnew$hp <- 200
forecast <- predict(reg.out, as.matrix(Xnew))

mean(forecast$predicted < mtcars$mpg)

```


bigKRLS: “Big” File Management

```{r}
#If N > 2,500 or if you supply big matrices, using save() and load() will crash your R session. 
# Instead you may do one of two things to save:

#Note: X and y should only contain numeric data (no missing data, factors, or vectors of constants) 
#  and may be base R matrices or “big” matrices (from bigmemory).
#
#For example:
# y = as.matrix(mtcars$mpg)
# X <- as.matrix(mtcars[,-1]) 
out <- bigKRLS(y, X, model_subfolder_name = "my_results")  
save.bigKRLS(out, "my_results") # not run

#Either will save the model estimates to a new subfolder called “my_results” in your current working directory. 
#To re-load,

load.bigKRLS("my_results")  

#When N > 2,500 or the user provides big matrices, big matrices will be returned, 
# which are really just memory addresses.

Z <- big.matrix(nrow=5, ncol=5, init=1)
Z

## An object of class "big.matrix"
## Slot "address":
## <pointer: 0x639c570>

#You do not necessarily need to work with the big square matrices in the output. 
#  But if you do and your comfortable they fit in memory, just use the square brackets:
  
Z[]
## [,1] [,2] [,3] [,4] [,5]
## [1,] 1 1 1 1 1
## [2,] 1 1 1 1 1
## [3,] 1 1 1 1 1
## [4,] 1 1 1 1 1
## [5,] 1 1 1 1 1

```
